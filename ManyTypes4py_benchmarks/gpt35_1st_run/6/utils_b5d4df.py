from typing import Any, List, Iterator, Iterable, Tuple, Dict, Optional, Union, TypeVar

def check_version(version: str) -> None:
    ...

def load_version(fname: str) -> str:
    ...

def parse_version(version_string: str) -> Tuple[str, str, str]:
    ...

def log_basic_info(args: Any) -> None:
    ...

def seed_rngs(seed: int) -> None:
    ...

def check_condition(condition: bool, error_message: str) -> None:
    ...

class OnlineMeanAndVariance:
    def update(self, value: float) -> None:
        ...

def chunks(some_list: List[Any], n: int) -> Iterator[List[Any]]:
    ...

def get_tokens(line: str) -> Iterator[str]:
    ...

def is_gzip_file(filename: str) -> bool:
    ...

def smart_open(filename: str, mode: str = 'rt', ftype: str = 'auto', errors: str = 'replace') -> Any:
    ...

def combine_means(means: List[float], num_sents: List[int]) -> float:
    ...

def combine_stds(stds: List[float], means: List[float], num_sents: List[int]) -> float:
    ...

def average_tensors(tensors: List[Any]) -> Any:
    ...

def gen_prefix_masking(prefix: Any, vocab_size: int, dtype: Any) -> Tuple[Any, int]:
    ...

def shift_prefix_factors(prefix_factors: Any) -> Any:
    ...

def adjust_first_step_masking(target_prefix: Any, first_step_mask: Any) -> Any:
    ...

def parse_metrics_line(line_number: int, line: str) -> Dict[str, Union[str, float, bool, None]]:
    ...

def read_metrics_file(path: str) -> List[Dict[str, Union[str, float, bool, None]]]:
    ...

def write_metrics_file(metrics: List[Dict[str, Union[str, float, bool, None]]], path: str) -> None:
    ...

def get_validation_metric_points(model_path: str, metric: str) -> List[Tuple[float, int]]:
    ...

def grouper(iterable: Iterable[Any], size: int) -> Iterator[List[Any]]:
    ...

def metric_value_is_better(new: float, old: float, metric: str) -> bool:
    ...

def dtype_to_str(dtype: Any) -> str:
    ...

def get_torch_dtype(dtype: Any) -> Any:
    ...

def get_numpy_dtype(dtype: Any) -> Any:
    ...

def log_parameters(model: Any) -> None:
    ...

def no_context() -> Iterator[None]:
    ...

class SingleProcessPool:
    def map(self, func: Any, iterable: Iterable[Any]) -> List[Any]:
        ...
    def starmap(self, func: Any, iterable: Iterable[Tuple[Any]]) -> List[Any]:
        ...
    def __enter__(self) -> 'SingleProcessPool':
        ...
    def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -> None:
        ...

def create_pool(max_processes: int) -> Union[SingleProcessPool, Any]:
    ...

def update_dict(dest: Dict[Any, Any], source: Dict[Any, Any]) -> None:
    ...

def update_dict_with_prefix_kv(dest: Dict[Any, Any], prefix_kv: Dict[str, Any]) -> None:
    ...

def is_distributed() -> bool:
    ...

def is_primary_worker() -> bool:
    ...

def get_local_rank() -> int:
    ...

def broadcast_object(obj: Any, src: int = 0) -> Any:
    ...

def all_gather_object(obj: Any) -> List[Any]:
    ...

def init_deepspeed() -> None:
    ...

def using_deepspeed() -> bool:
    ...

def check_import_faiss() -> None:
    ...

def count_seq_len(sample: str, count_type: str = 'char', replace_tokens: Optional[List[str]] = None) -> int:
    ...

def compute_isometric_score(hypothesis: str, hypothesis_score: float, source: str, isometric_metric: str = 'isometric-ratio', isometric_alpha: float = 0.5) -> float:
    ...

def init_device(args: Any) -> Any:
    ...

def fault_tolerant_symlink(src: str, dst: str, max_retries: int = 6) -> None:
    ...
